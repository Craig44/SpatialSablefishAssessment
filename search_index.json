[["index.html", "SpatialSablefishAssessment Introduction", " SpatialSablefishAssessment C.Marsh 2023-07-24 Introduction SpatialSablefishAssessment is a R package for conducting spatial stock assessment research for a stock that has two fisheries and sexed population. library(TMB) library(SpatialSablefishAssessment) #devtools::install_github(&quot;Craig44/SpatialSablefishAssessment&quot;) library(ggplot2) library(dplyr) "],["a-list-of-functions-available-in-the-spatialsablefishassessment-package.html", "A list of functions available in the SpatialSablefishAssessment package", " A list of functions available in the SpatialSablefishAssessment package All of these functions have descriptions and details on expected input parameters using the standard ? R query methods. You can also use help(package = \"SpatialSablefishAssessment\") to get a list of functions available in this package. Most of the functions will ask for an optional input parameter called region_key which will add a label for regions. This is a data.frame which is shown in the following code chunk. Note how the column TMB_ndx is an index made for C++ syntax not R i.e., it starts at 0 not 1. region_key = data.frame(area = c(&quot;BS&quot;,&quot;AI&quot;,&quot;WGOA&quot;,&quot;CGOA&quot;,&quot;EGOA&quot;), TMB_ndx = c(0:4)) region_key ## area TMB_ndx ## 1 BS 0 ## 2 AI 1 ## 3 WGOA 2 ## 4 CGOA 3 ## 5 EGOA 4 Validate functions validate_input_data_and_parameters This should always be run on data and parameters applying TMB::MakeADFun. It should catch any issues that will likely cause your R session to crash. Accessor functions get_AF get age-frequency observed and predicted values from a model get_LF get length-frequency observed and predicted values from a model get_catches get observed and predicted catches from a fitted model get_fishing_mortalities get annual fishing mortalities from a model get_index get survey index from a model get_partition get numbers at age (units 1 = 1e6) from a fitted model get_SSB get SSBS (kilo tonnes) from a fitted model get_tag_recovery_obs_fitted_values get_tag_release_AF get age-frequency of tag-releases get_negloglike get negative log likelihoods for each contribution get_comp_sample_size get composition sample size simulate_observations this function will take a TMB object and simulate a number of observations, used to create simulated residuals. calculate_simulated_residuals this function will take an element from an object created from simulate_observations. This will use DHARMas createDHARMa function to calculated simulated residuals Plotting functions plot_AF plot age frequency observation plot_age_length_matrix plot input age-length transition matrices plot_catch_fit plot the fit to catches plot_fishing_mortalities plot fishing mortalities plot_frequency_of_tag_release_and_recoveries plot_index_fit plot survey index plot_init_nage plot initial numbers at age plot_input_catches plot input catches plot_input_observations plot input observations plot_input_timeblocks plot selectivity and catchability time-blocks in a model plot_comp_sample_size plot composition sample size plot_LF plot length frequency observation plot_mean_age plot mean age observations plot_mean_length plot mean length observations plot_mean_weight plot mean weight over time for males and females plot_movement plot movement matrix from a model plot_partition plot numbers at age by year and sex plot_recruitment plot annual recruitment by region plot_selectivities plot selectivity curves plot_SSB plot regional SSBs plot_tag_recovery_obs plot tag-recovery obs plot_tag_recovery_fits an alternative plotting function for tag-recovery obs plot_tag_release_AF plot the numbers at age by sex for each release event Estimation functions profile_param Run log-likelihood profiles on an estimated parameter set_up_parameters Fix parameters, uses fix_pars and set_pars_to_be_the_same for the TagIntegrated model pre_optim_sanity_checks run some checks on a TMB model of type TagIntegrated before optimization post_optim_sanity_checks run some checks on a TMB model of type TagIntegrated after optimization check_gradients check all parameter gradients are not zero Francis_reweighting calculate stage-two weights for composition data get_tmb_fixed_effects return fixed effect parameters from a model fix_pars turn off parameters so they arent estimated, there are many parameters that shouldnt be estimated set_pars_to_be_the_same set parameters to be estimated at the same value i.e., male female have the same selectivity parameters. or tag-reporting to be the same among regions. rmvnorm_prec simulate from a multivariate normal distribution using the precision matrix. Projection/Reference point functions setup_proj_data this function will take an estimation model and create a data list that when built with TMB::MakeADFun creates a model that will projections for a user defined number of projection years. find_regional_Fspr this will attempt to find an F for each region and fishery assuming future deterministic (mean) recruitment that achieves some specified target percent \\(B_{0}\\) in each region. Model comparison functions Often you will run multiple models to explore alternative assumptions and hypothesis. There are a range of function available for extracting output convenient for plotting and summarizing. In order to use the following functions you need to create a list containing multiple runs e.g. multi_runs &lt;- list() multi_runs[[1]] &lt;- low_M_model$report() multi_runs[[2]] &lt;- high_M_model$report() run_labels = c(&quot;M = 0.08&quot;, &quot;M = 0.2&quot;) ssb_df = get_multiple_ssbs(mle_ls = multi_runs, run_labels = run_labels) get_multiple_ssbs get multiple models SSBs get_multiple_catch_fits Get multiple models catch fits get_multiple_nlls get multiple models negative log-likelihood summarise_individual_models this is a function that will build a Bookdown/Rmarkdown book displaying a full summary of each model individually. This functions expect users to save the following objects with these exact names for each model that you want to compare. Then pass the function all the directories with model labels and descriptions. Then it should automatically build you a Rmarkdown document. saveRDS(data, file.path(fig_path, &quot;data.RDS&quot;)) saveRDS(parameters, file.path(fig_path, &quot;parameters.RDS&quot;)) saveRDS(mle_report, file.path(fig_path, &quot;mle_report.RDS&quot;)) saveRDS(sd_report, file.path(fig_path, &quot;sd_report.RDS&quot;)) saveRDS(mle_spatial, file.path(fig_path, &quot;mle_optim.RDS&quot;)) saveRDS(map_fixed_pars, file.path(fig_path, &quot;map_fixed_pars.RDS&quot;)) saveRDS(region_key, file.path(fig_path, &quot;region_key.RDS&quot;)) summarise_multiple_models this is a function that will build a Bookdown/Rmarkdown book compareing multiple models fits and quantities on the same plot. This functions expect users to save the following objects with these exact names for each model that you want to compare. Then pass the function all the directories with model labels and descriptions. Then it should automatically build you a Rmarkdown document. saveRDS(data, file.path(fig_path, &quot;data.RDS&quot;)) saveRDS(parameters, file.path(fig_path, &quot;parameters.RDS&quot;)) saveRDS(mle_report, file.path(fig_path, &quot;mle_report.RDS&quot;)) saveRDS(sd_report, file.path(fig_path, &quot;sd_report.RDS&quot;)) saveRDS(mle_spatial, file.path(fig_path, &quot;mle_optim.RDS&quot;)) saveRDS(map_fixed_pars, file.path(fig_path, &quot;map_fixed_pars.RDS&quot;)) saveRDS(region_key, file.path(fig_path, &quot;region_key.RDS&quot;)) Distribution functions ddirichmult Dirichlet-multinomial pdf function dmultinom_upd Multinomial pdf function, which is the same as TMBs. Differs from Rs base dmultinom by allowing non-integer x values and not rounding the x values. lognormal_CI calculate confidence intervals for the lognormal distribution log_cv calculate cv for the lognormal distribution given standard deviation log_sigma calculate standard deviation for the lognormal distribution given CV Parameter transformation functions restoresimplex go from simplex to unit vector simplex go from unit vector to simplex logit_general logistic transformation between a specified lower and upper bound logit logistic transformation between 0, 1 similar to qlogis invlogit_general inverse logistic transformation between a specified lower and upper bound invlogit inverse logistic transformation between 0, 1 similar to plogis bound_unit transform a parameter \\(X\\) bound between -1 and 1 (i.e., correlation parameter) to value \\(Y\\) which is unbounded as \\[ Y = \\begin{cases} \\sqrt{\\frac{X^2}{1 - X^2}}, \\ \\ &amp; X \\geq 0 \\\\ -\\sqrt{\\frac{X^2}{1 - X^2}} , \\ \\ &amp; X &lt; 0 \\end{cases} \\] inv_bound_unit inverse of bound_unit gm_mean calculate the geometric mean sum_to_zero_QR take an unconstrained vector of length N - 1 and calculate a vector of length N that sums = 1. Data grooming functions These arent related to the model per se. These are useful when grooming raw data sets that are ultimately used as inputs into the model. record_grooming_rule this will create a table of how much catch and how many records are removed from applying some data grooming rules apply_grooming_rule equivalent to the subset function Auxillary functions VAlignPlots a plotting function that joins multiple ggplots into a single panel with aligned legends and extents "],["how-to-use-spatialsablefishassessment.html", "How to use SpatialSablefishAssessment Configuring and checking model inputs (data and parameters) Optimisation Model Summary", " How to use SpatialSablefishAssessment Configuring and checking model inputs (data and parameters) This package contains TMB models and summarizing and plotting functions for a spatial model used in sablefish research. Users are responsible for configuring the data and parameter structures that are passed to the TMB MakeADFun function which compiles the model. The best place to look for what dimensions and names of expected elements for data and parameter it is best to look at an example or the source code for the model (see here). To view an example data run load(system.file(&quot;testdata&quot;, &quot;MockSablefishModel.RData&quot;,package=&quot;SpatialSablefishAssessment&quot;)) names(data) names(parameters) region_key Once you have built the data and parameter objects then you can check that the dimensions are consistent with the model by using, validate_input_data_and_parameters(data, parameters) This function will report a message telling you either success or if one of the objects dimensions are off, then you will need to fix this because it is likely if you pass this to the TMBs MakeADFun it will crash your R session. The following list are some useful utility functions contained in this package to visualize data inputs. All functions should be documented and queried using the usual R ? method plot_input_observations plot_input_catches plot_mean_weight plot_age_length_matrix Once you have checked the data and parameter objects you can build the TMB model following, my_model = TMB::MakeADFun(data = data, parameters = parameters, DLL = &quot;SpatialSablefishAssessment_TMBExports&quot;, silent = T) Simple sanity checks It is possible to configure a model that has zero gradients for parameters, and you want to check this is not the case using the ## check gradients and NA&#39;s in likelihoods pre_optim_sanity_checks(my_model) Optimisation mle_optim = nlminb(start = my_model$par, objective = my_model$fn, gradient = my_model$gr, control = list(iter.max = 10000, eval.max = 10000)) # Try and improve the optimsation running the model for two additional Newton Raphson iterations try_improve = tryCatch(expr = for(i in 1:2) { g = as.numeric(my_model$gr(mle_optim$par)) h = optimHess(mle_spatial$par, fn = my_model$fn, gr = my_model$gr) mle_optim$par = mle_spatial$par - solve(h,g) mle_optim$objective = my_model$fn(mle_optim$par) } , error = function(e){e}) try_improve ## should be NULL i.e., no error or warning otherwise suggests non-PD hessian matrix Check convergence ## check PD covariance ## check parameters at bounds ## check final gradients ## check eigen value sizes post_optim_sanity_checks(my_model) Fixing estimable parameters at input values ?fix_pars() Sharing parameter estimates among estimable variables i.e., male and female having a common selectivity ?set_pars_to_be_the_same() For the TagIntegrated there is a specific function set_up_parameters which will set up the map object used by TMBs MakeADFun which will fix values at input values during optimization and set shared parameters. ?set_up_parameters() Model Summary Once you are satisfied that the model has converged at global minimum, then you can get the model to report model quantities ## get MLE quantities mle_report = my_model$report(mle_optim$par) ######### ## Plot interesting ## Model quantities i.e., recruitment SSBs model fits etc ######### ## movement assumption plot_movement(mle_report, region_key = region_key) # starting values plot_movement(OM_report, region_key) # plot selectivities plot_selectivities(mle_report) # starting values plot_selectivities(OM_report) ## Regional SSBs ssb_plt = plot_SSB(mle_report, region_key = region_key) ssb_plt ## sum SSB over all regions ggplot(ssb_plt$data %&gt;% group_by(Year) %&gt;% summarise(total_ssb = sum(SSB)), aes(x = Year, y = total_ssb)) + geom_line(linewidth = 1.1) + ylim(0,NA) ## plot F&#39;s plot_fishing_mortalities(MLE_report = mle_report, region_key = region_key) ## plot fits to observations # catch and index plot_catch_fit(MLE_report = mle_report, region_key = region_key) + facet_wrap(label~Region, ncol = n_regions) + ylab(&quot;Catch (mt)&quot;) plot_index_fit(MLE_report = mle_report, region_key = region_key) # survey AFs first_year_set = c(1981, seq(from = 1985, to = 1993, by = 2), 1996:1999) plot_AF(MLE_report = mle_report, region_key = region_key, label = &quot;srv_dom_ll&quot;, subset_years = first_year_set, sex = &quot;male&quot;) + ggtitle(&quot;Male survey AF&quot;) + guides(shape = &quot;none&quot;, linetype = &quot;none&quot;) + ylim(0,20) plot_AF(MLE_report = mle_report, region_key = region_key, label = &quot;srv_dom_ll&quot;, subset_years = first_year_set, sex = &quot;female&quot;) + ggtitle(&quot;Female survey AF&quot;) + guides(shape = &quot;none&quot;, linetype = &quot;none&quot;) # fishery LFs # Fixed gear plot_LF(MLE_report = mle_report, region_key = region_key, label = &quot;fixed&quot;, subset_years = 1991:1999, sex = &quot;male&quot;) + ggtitle(&quot;Male fixed LF&quot;) + guides(shape = &quot;none&quot;, linetype = &quot;none&quot;) plot_LF(MLE_report = mle_report, region_key = region_key, label = &quot;fixed&quot;, subset_years = 1991:1999, sex = &quot;female&quot;) + ggtitle(&quot;Female fixed LF&quot;) + guides(shape = &quot;none&quot;, linetype = &quot;none&quot;) # plot by tag releases event tag_fits_by_age_sex = get_tag_recovery_obs_fitted_values(mle_report, region_key = region_key) tag_fits = tag_fits_by_age_sex %&gt;% group_by(release_event, unique_recovery_id) %&gt;% summarise(observed = sum(observed), predicted = sum(predicted), recovery_year = unique(recovery_year), recovery_region = unique(recovery_region), release_region = unique(release_region), release_year = unique(release_year)) tag_fits$resid = tag_fits$observed - tag_fits$predicted tag_fits$stand_resid = tag_fits$resid / tag_fits$predicted tag_fits$resid_sign = ifelse(tag_fits$resid &lt; 0, &quot;negative&quot;, &quot;positive&quot;) unique_release_events = unique(tag_fits$release_event) gplt = ggplot(tag_fits %&gt;% filter(release_event %in% unique_release_events[1:16]), aes(x = recovery_year, y = recovery_region)) + geom_point(aes(size = abs(stand_resid), col = resid_sign)) + labs(x = &quot;Recovery year&quot;, y = &quot;Recovery region&quot;, size = &quot;Pearson residuals&quot;) + theme_bw() + scale_size_area() + facet_wrap(~release_event) + scale_x_discrete(breaks = every_nth(n = 5)) "],["tagintegrated-model-equations.html", "TagIntegrated model equations Process equations Observation equations Likelihood formulations Projecting Symbol Notation", " TagIntegrated model equations Process equations Population dynamics The order of processes in an annual cycle follow recruitment and release of tagged fish (we apply initial tag induced mortality here), total mortality and ageing, markovian movement annual tag shedding (applied as a mortality process), Before movement, the partition is updated following \\[\\begin{align*} N_{a,r,y,s} = \\begin{cases} R_{r,y} p^R_{s,y}, &amp; a = a_1\\\\ N_{a - 1,r,y - 1,s} \\exp\\bigg( -Z_{a - 1,r, y - 1,s} \\bigg), &amp; a_1 &lt; a &lt; a_+\\\\ N_{a - 1,r,y - 1,s} \\exp\\bigg( -Z_{a - 1,r, y - 1,s} \\bigg) + N_{a,r,y - 1,s} \\exp\\bigg( -Z_{a,r, y - 1,s} \\bigg), &amp; a = a_+ \\end{cases} \\end{align*}\\] \\(p^R_{s,y}\\) is proportion recruits for sex \\(s\\) in year \\(y\\) and movement is then applied \\[\\begin{equation*} \\boldsymbol{N}&#39;_{a,y,s} = \\boldsymbol{N}_{a,y,s} \\boldsymbol{M} \\ \\ \\forall \\ a \\end{equation*}\\] where, \\(\\boldsymbol{N}&#39;_{a,y,s} = (N&#39;_{a,1,y,s}, \\dots, N&#39;_{a,n_r,y,s})\\) denotes the numbers for age \\(a\\) across all regions after movement and \\(\\boldsymbol{M}\\) is an \\(n_r \\times n_r\\) movement matrix, which will move age cohort \\(a\\) among the regions based on the movement matrix. ** An important input is whether movement occurs to new recruits, which is specified by the input do_recruits_move. If do_recruits_move == 0 i.e., they dont get movement applied. In the code this applied by applying movement and then resetting the numbers at age by the recruited values. Initialisation An equilibrium age structure is derived by iterating the annual cycle is run \\(n_a - 1\\) times (i.e., to populate all age cohorts prior to the plus group). Then, iterate the annual cycle one more time and calculate the number of individuals that moved into each regions plus age cohort, denoted by \\(c^r_{a+}\\). This will be the result of ageing, mortality and movement. The equilibrium plus group for region \\(r\\) is then calculated as \\[ N_{a+, r} = N_{a+ - 1, r} \\frac{1}{1 - c^r_{a+}} \\ . \\] After the equilibrium age-structure is calculated, there is an option to estimate global or region specific deviations to allow the model to start with a non-equilibrium age-structure \\[ N_{a, r} = N_{a, r} e^{\\psi_a} \\ \\ \\forall \\ r \\ \\&amp; \\forall a \\in (a_{min} + 1, \\dots, a_{max} - 1) \\] These estimatble intiial age-deviations are not applied on the first or last age cohort. This is what is done in the current Sablefish assessment, I think it has something to do with helping estimation of \\(R_0\\) and such. There is the ability to estimate less age-deviations than age using data$n_init_rec_devs. If there are 30 age-cohorts in the model you can set up initial age-deviations so only 15 are estimated with ages 16-29 getting applied the same last \\(e^{\\psi_a}\\) value. To help with estimation, there is a penalty on \\(\\psi_a\\) that assumes a central tendancy of zero with an estimable variance parameter (\\(\\sigma_{\\psi}^2\\)). \\[ \\psi_a \\sim \\mathcal{N}(0, \\sigma_{\\psi}) \\] In general these parameters can be highly uncertain. The variance on these deviation parameters is often fixed at a low value which requires a strong signal in the data to deviate away from the initial equilibrium age-structure. You can also apply/estimate additional fishing mortality during the initial equilibrium calculation denoted by \\(F^{init}_{a,s}\\) for age \\(a\\) and sex \\(s\\). If F_method = 0 then \\[ F^{init}_{a,s} = F^{fixed} S_{a,s}^{fixed} p_{hist} \\] where, \\(F^{fixed}\\) is the average annual fishing mortality for the fixed gear (ln_fixed_F_avg), \\(S_{a,s}^{fixed}\\) is the fixed gear selectivity in the first time-block and \\(p_{hist}\\) is an input value that specifies the proportion of average longline fishing mortality to apply during initialisation. If F_method = 1 then \\[ F^{init} = \\widehat{F}^{init}S_{a,s}^{fixed} p_{hist} \\] where, \\(\\widehat{F}^{init}\\) is the estimable parameter ln_init_F_avg. It is advised to set \\(p_{hist} = 1.0\\) so that the estimated parameter has a natural interpretation. There are two initial biomass quantities that are reported, these are Bzero and Binit. Bzero is the spawning biomass from a population that has been exposed to natural mortality, recruitment (\\(R_0\\)), and movement only. Binit is the spawning biomass from a population that has been exposed to natural mortality and initial fishing mortality (\\(F^{init}\\)), recruitment (\\(R_0\\)), and movement. Growth Empirical length at age matrices are supplied for all years where sufficient age-length data was available and growth was assumed the same across all regions. Mean weight at age is also an user input. Growth cannot vary across regions in the current models, so users must supply length at age matrices and weight at age vectors for each year, age and sex in the model. Recruitment How to spatially apportion recruits in a way that is consistent with the data and isnt confounded with movement of young fish? There are two considerations, firstly looking at the AF and LFs there are regions that seem to have more young fish than others (link to figure and describe). However, there is very little information on spawning grounds and behavior. This coupled with a complex early life history make it difficult to a priori set regional apportionment of recruits, which would be ideal, an alternative is to estimate these as free parameters. This may introduce confounding when we start estimating movement which is believed to be ontogenetic. Terminology regarding recruitment and spatial population structures can be ambiguous and confusing. There is a fair bit of literature describing and comparing metapopulations, panmictic populations and spatially heterogeneous populations. I believe this model can represent the later two A metapopulation implies there is some natal identifiability when fish are mixing which this model doesnt do. However, this would only be advantageous when there is some sort of natal dynamic e.g. natal homing or natal productivity difference such as growth. Neither of these are really evident in the observed data for sablefish and so having a natal attribute in the partition doesnt make much sense. Spawning biomass Spawning biomass is based on mature female weight. SSB in a given year and region is calculated as, \\[ SSB_{y,r} \\sum\\limits_a N_{a,s = 2, r, y} exp(-Z_{a,s = 2, r, y})^{prop_Z} S^{mat}_{a,y} \\bar{w}_{a,s = 2, y} \\] where, \\(s = 2\\) denotes the female sex, \\(S^{mat}_{a,y}\\) is the maturity at age, \\(\\bar{w}_{a,s = 2, y}\\) is female mean weight at age and \\(prop_Z\\) indicates the proportion of total mortality applied before SSB is calculated. Fishing mortality When the hybrid \\(F\\) method is assumed, tagged fish were not included when internally solving the fishing mortality nuisance parameters. The ratio of tagged to untagged numbers of fish in the partition in any year was assumed to be small enough not to effect \\(F\\) estimates. However, tagged fish were included when the model calculates predicted catch-at-age/length and catch for a fleet. This decision was made to reduce the computational overhead this would require to implement. When \\(F\\) parameters are estimated as free parameters, then this is not a problem and \\(F\\) will be applied to both tagged and untagged fish. Tag release events Tags release event denoted by the index \\(k\\) have an implied region \\(r\\) and year \\(y\\) dimension. Each tag release event has known sex and age frequency at release. Often tagging data has only length at release information, we have used age-length keys to convert numbers at length of release to numbers at age and sex at release that are then input into the model (data$male_tagged_cohorts_by_age and data$female_tagged_cohorts_by_age). Tagged fish from release event \\(k\\) are denoted in the partition by \\(N^k_{a,r,y,s}\\), and are tracked for \\(n_{T}\\) (data$n_years_to_retain_tagged_cohorts_for) years before migrating into an accumulation tag group, at which point we loose release-year information but do maintain release region. At present, tagged fish are assumed to take on the exact same population processes as the untagged elements of the partition i.e., no mixing periods. Something to consider, given there is uncertainty in the age-length key method, when converting numbers at length to numbers at age and sex and the numbers of tag-releases are assumed known without error. Consider rerunning the model with bootstrapped tag releases from bootstrapped age-length keys. This will give you an indication of the uncertainty the model has to this input assumption. Selectivities Describe the functional forms available in the models. The selectivity component is quite modular and you can easily add a new selectivity function in the source code here. There are three selectivities in the model one for the survey and two for the fisheries. Selectivities types are set by the model data objects ending with sel_type e.g., fixed_sel_type, trwl_sel_type and srv_dom_ll_sel_type. These objects are vectors each element defines a selectivity type that is applied in a time-block. The time-block is defined by the corresponding sel_by_year_indicator objects. The following is an example of how to specify and interpret these containers. Say data$years = c(1990, 1991, 1992, 1993) and we were not interested in doing projections (require more elements in sel_by_year_indicator objects). Say we wanted to have 1990 and 1991 have one logistic selectivity and then 1992 and 1993 to have seperate logistic selectivity for the fixed gear fishery, you would specify the containers as data$fixed_sel_type = c(0, 0) data$fixed_sel_by_year_indicator = c(0, 0, 1, 1) this points each model year to a selectivity in data$fixed_sel_type Selectivity types are 0 Logistic \\[ S(a | \\theta_1, \\theta_2) = \\frac{1}{1 + \\exp(-\\theta_2 \\times (a - \\theta_1)} \\] 1 Double normal - Punt et. al 1996 gamma parameterization (that is a comment from the ADMB assessment code) \\[ S(a | \\theta_1, \\theta_2) = \\frac{a}{\\theta_1}^{\\theta_1/0.5\\sqrt{\\theta_1^2 + 4\\theta_2^2}} exp\\left(\\frac{\\theta_1 - a}{0.5 \\left( \\sqrt{\\theta_1^2 + 4\\theta_2^2} - \\theta_1 \\right)} \\right) \\] 2 power function (Be careful with this selectivity, if your min age is not = 1. Then I dont think you will end up with a max selectivity value of 1) \\[ S(a | \\theta_1) = \\frac{1}{a ^{\\theta_1}} \\] 3 Alternative logistic \\[ S(a | \\theta_1, \\theta_2) = \\frac{1}{1 + 19^{(\\theta_1 - a) / \\theta_2}} \\] 4 Exponential decay \\[ S(a | \\theta_1) = exp(-a * \\theta_1); \\] 5 Double normal 3 parameterisation, where \\(\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\theta_3) = (\\mu, \\sigma_r, \\sigma_l)\\), where \\(\\mu\\) is the age that the selectivity = 1, \\(\\sigma_r\\) is the standard deviation for the right hand side of the selectivity curve and \\(\\sigma_l\\) is the standard deviation for the left hand side of the selectivity curve \\[ S(a | \\mu, \\sigma_r, \\sigma_l) = j_a \\exp\\left(\\log(0.5) \\left(\\frac{a - \\mu}{\\sigma_r^2}\\right)^2\\right) + \\left( 1 - j_a \\right)\\exp\\left(\\log(0.5) \\left(\\frac{a - \\mu}{\\sigma_l^2}\\right)^2\\right) \\] where, \\[ j_a = 1 / \\left(1 + \\exp\\{-5(a - \\mu)\\}\\right) \\] Observation equations There are five observation types available in the TagIntegrated model Relative indices of abundance from a longline survey (its called longline survey but could be any survey) Age composition disaggregated by sex for the fixed gear fishery and longline survey Length composition disaggregated by sex for the trawl and fixed gear fishery Annual observed catch by fishery Tag recoveries from the fixed gear fishery Catch at age Fishery dependent catch at age observations are available for the fixed gear fishery, but are also needed to calculate catch at length observations for the trawl fishery. Catch at age for fishery \\(g\\) is denoted by \\({C}^g_{a,r,y,s}\\) and model fitted values are calculated following \\[\\begin{equation} {C}^g_{a,r,y,s} = \\frac{F^g_{a,r,y,s}}{Z_{a,r,y,s}} N_{a,r,y,s} \\left(1 - S_{a,r,y,s} \\right) \\end{equation}\\] Observed values were proportions with respect to age and sex, final model fitted proportions were \\[ {P}^g_{a,r,y,s} = \\frac{{C}^g_{a,r,y,s}}{\\sum_a \\sum_s {C}^g_{a,r,y,s}}, \\] if the multinomial distribution is assumed \\[ \\boldsymbol{X}^g_{r,y} \\sim \\text{Multinomial}\\left(\\boldsymbol{\\widehat{P}}^g_{r,y}\\right) \\] where, \\(\\boldsymbol{X}^g_{r,y} = \\boldsymbol{P}^g_{r,y}N^{eff}_{r,y}\\) and \\(\\boldsymbol{P}^g_{r,y}\\) is the observed proportions, \\(N^{eff}_{r,y}\\) is the effective sample size and \\(\\boldsymbol{P}^g_{r,y} = (P^g_{1,r,y,1}, \\dots, P^g_{a_+,r,y,1}, P^g_{1,r,y,2}, \\dots, P^g_{a_+,r,y,2})\\) is the vector of observed proportions across all ages and sexs in year \\(y\\) and region \\(r\\), and \\(\\boldsymbol{\\widehat{P}}^g_{r,y}\\) is the model fitted values which have the same dimension (\\(\\sum_a \\sum_s \\widehat{P}^g_{a,r,y,s} = 1\\)). Catch at length Catch at length observations are available for the trawl fishery. Model fitted values are derived by multiplying the catch at age (see above) by an age-length transition matrix denoted by \\(\\boldsymbol{A}^l_{y,s}\\) (dimensions of \\(\\boldsymbol{A}^l_{y,s}\\) are \\(n_a \\ \\times \\ n_l\\) and its rows must sum to 1), \\[\\begin{equation} \\widehat{\\boldsymbol{Cl}}^g_{r,y,s} = \\left(\\boldsymbol{A}^l_{y,s} \\right)^T \\ \\times \\ \\widehat{\\boldsymbol{C}}^g_{r,y,s} \\end{equation}\\] where, \\(\\widehat{\\boldsymbol{C}}^g_{r,y,s}\\) is a column vector of catch at age (dimension \\(n_a \\ \\times \\ 1\\)) at the beginning of year \\(y\\) in region \\(r\\) for sex \\(s\\), and \\(\\widehat{\\boldsymbol{Cl}}^g_{r,y,s}\\) is a column vector of catch at length (dimension \\(n_l \\ \\times \\ 1\\)). Proportions at age Survey age composition data denoted by \\({N}^s_{a,r,y,s}\\) is available for the longline survey where model fitted numbers are derived as, \\[\\begin{equation} \\widehat{N}^s_{a,r,y,s} = N_{a,r,y,s} \\left(1 - \\exp^{\\delta_y Z_{a,r,y,s}}\\right)S^s_{y,r,a,s} \\end{equation}\\] where, \\(\\delta_y \\in (0,1)\\) is the proportion of time in the year that the observation occurs during year \\(y\\) and \\(S^s_{y,r,a,s}\\) is the survey selectivity. Relative abundance indices \\[\\begin{equation} \\widehat{I}^s_{r,y} = \\sum_s\\sum_a \\widehat{N}^s_{a,r,y,s} \\bar{w}_{a,y,s} \\end{equation}\\] where, \\(\\bar{w}_{a,y,s}\\) is mean weight at age, this can be omitted if the observation is in numbers i.e., abundance instead of biomass using data$srv_dom_ll_obs_is_abundance = 1. There are currently two likelihoods available for this observation if data$srv_dom_ll_bio_comp_likelihood == 0 \\[ ll_{r,y} = \\frac{\\left( \\log {I}^s_{r,y} + 0.0001 - \\log \\widehat{I}^s_{r,y} + 0.0001 \\right)^2}{2 \\left( SE[{I}^s_{r,y}] / {I}^s_{r,y} \\right)} \\] if data$srv_dom_ll_bio_comp_likelihood == 1 \\[ ll_{r,y} = \\frac{1}{{I}^s_{r,y} SE[{I}^s_{r,y}] \\sqrt{ 2\\pi}} \\exp \\left( - \\frac{ \\left(\\log {I}^s_{r,y} - \\log \\widehat{I}^s_{r,y} - 0.5SE[{I}^s_{r,y}]^2\\right)^2}{2 SE[{I}^s_{r,y}]^2}\\right) \\] The catchability coefficient can also be calculated as a nuisance parameter instead of a free estimable parameter using the input data$q_is_nuisance = 1. This will solve the value for q in each region conditional on the other input free parameters. If the abundance or biomass observation is assumed to be lognormally distributed, then we can algebraically solve for the catchability coefficient. For simplicity in the following equations we use \\(E_i\\) to denote the model expected value \\(O_i\\) to denote the observed value and \\(\\sigma_i\\) to denote the standard error for element \\(i\\) of a series. In this case a time-series is within each region. So we will calculate a nuisance q for each region. Technically, this derivation is only correct when data$srv_dom_ll_bio_comp_likelihood == 1 however, it will be considered an approximation for the other likelihood. Assuming a specific element contributes to the negative log likelihood in the following manor, \\[ -ll = \\sum_i log (\\sigma_i) + 0.5\\sum_i \\bigg(\\frac{log(O_i) - log(qE_i) + 0.5\\sigma_i^2}{\\sigma_i} \\bigg)^2 \\ , \\] then, if you differentiate this term with respect to \\(q\\) you get \\[ \\frac{\\partial }{\\partial q}(-ll) = \\frac{-1}{q} \\sum_i\\bigg( \\frac{log(O_i/E_i) - log(q) + 0.5\\sigma_i^2}{\\sigma_i^2}\\bigg) \\, \\] if you solve for when the derivative is zero (MLE estimate) then you obtain the following result \\[ \\hat q = exp\\frac{0.5n + S_3}{S_4} \\, \\] where \\(S_3 = \\sum_i (log(O_i /E_I)/\\sigma_i^2)\\) and \\(S_4 = \\sum_i(1/\\sigma_i^2)\\). \\(E_i\\) in the initial calculation is derived assuming a \\(q = 1\\), before \\(\\hat q\\) is calculated. Tag recovery observations When tagged fish are released in to the model partition they are tracked by the tag release event index denoted by \\(k\\) for \\(n_{T}\\) years after release. Due to tags being predominately recovered by the fixed gear fishery, all recoveries are assumed from the fixed gear fishery. A tag recovery observation will depend on if it is release conditioned or recapture conditioned. If tag-observations are release conditioned (the default) then for each release event there is a maximum of \\(n_{T} \\times n_r + 1\\) recovery possibilities, assuming the fixed gear fishery operates in all regions and all years we tracked the release event for. The plus one is for the not-recovered event, although it is not clear to me how this is different from a zero recovery event? (ask Dan). Let \\(m\\) index a recovery event for a given release event and let \\(n_{m|k} = n_{T} \\times n_r + 1\\) where \\(n_{m|k}\\) is the number of recovery events for release event \\(k\\). Let \\(N^k_{m}\\) denote the number of tag-recoveries for a given release and recovery combination, and \\(\\boldsymbol{N^k} = (N^k_{1}, N^k_{2}, \\dots, N^k_{n_{m|k}})^T\\) represents a vector of all possible observed recoveries for release event \\(k\\). Model fitted values for \\(N^k_{m}\\) are calculated as \\[ \\widehat{N}^k_{m} = \\sum_a \\sum_s N^k_{a,r,y,s} \\frac{F^{LL}_{a,r,y,s}}{Z_{a,r,y,s}} (1 - e^{-Z_{a,r,y,s}})\\delta_y \\ \\ y,r \\in m|k \\] where, \\(N^k_{a,r,y,s}\\) is the number of tagged fish alive from tag-release event \\(k\\), and \\(\\delta_y\\) is the reporting rate in year \\(y\\). There are three likelihoods used in the literature for tag-recoveries, The Poisson (tag_likelihood = 0) \\[ N^k_{m} \\sim \\mathcal{Poisson}(\\widehat{N}^k_{m}) \\] The Negative Binomial (tag_likelihood = 1) \\[ N^k_{m} \\sim \\mathcal{NB}(\\widehat{N}^k_{m}, \\hat{\\phi}) \\] where, \\(\\hat{\\phi}\\) is the estimable dispersion parameter Multinomial (tag_likelihood = 2) \\[ \\boldsymbol{N^k} \\sim \\text{Multinomial}\\left(\\boldsymbol{\\hat{\\theta}}^k, \\text{Neff}^k\\right) \\] All the recovery states include all regions, and years of recoveries including the non recaptured, where, \\(\\boldsymbol{\\hat{\\theta}}^k = (\\hat{\\theta}^k_1, \\hat{\\theta}^k_2\\dots, \\hat{\\theta}^k_{n_{m|k}})\\) is the proportions of all recovery states (Vincent, Brenden, and Bence 2020; Goethel, Legault, and Cadrin 2014), with \\[\\begin{equation} \\hat{\\theta}^{k}_{m} = \\frac{\\widehat{N}^k_{m}}{\\sum_m \\widehat{N}^k_{m}} \\end{equation}\\] For recapture conditioned tag-recovery observations, we calculate the probability of capture a fish at time \\(t\\) being released in region \\(r\\) and recovered in region \\(r&#39;\\). This was explored by McGarvey and Feenstra (2002). In this study they show how many of the terms can be dropped when describing the probability of that recovery event. The term \\(S_i[a_t, a_m]\\) represents the probability of a tagged individual tagged at \\(a_t\\) surviving until \\(a_m\\). In our model this surviorship will be regional specific, i.e., fish in certain regions will be exposed to higher fishing mortality rates than other regions over time. Here, model predicted recaptures are recapture conditioned, which means the predicted proportions are year specific, and represent the proportion of recaptures in each region, \\(\\boldsymbol{\\hat{\\theta}}^k_y = (\\hat{\\theta}^{k}_{y,1},\\dots, \\hat{\\theta}^k_{y,n_r})&#39;\\) \\[\\begin{equation} \\hat{\\theta}^{k}_{y,r} = \\frac{\\widehat{N}^k_{r,y}}{\\sum_r\\widehat{N}^k_{r,y}} \\end{equation}\\] How to deal with the high number of zeros in \\(\\boldsymbol{N^k}\\) zero inflated? These are derived for each recovery event (also year and region specific) denoted by the index \\(m\\) and tag-release event by using the age-length key that was used to release each recovered fish to obtain an sex specific age-frequency. This age-frequency is then aged by the number of years this tag-recovery event was at liberty to derive observed tag-recoveries by age and sex. This assumes the age-length conversion between releases and recoveries is consistent and allows us to use recovered fish with no length or sex recorded, but has the down side as mentioned earlier in the tag release section of smearing a single recovered fish across multiple age bins and sexes. However, it does mitigate the problem of going backwards and forwards through the age-length transition matrix, which appears to be more problematic. Multinomial (Not implemented) \\[ {N}^k_{r,y} \\sim \\text{Multinomial}\\left(\\boldsymbol{\\hat{\\theta}}^k_y, \\text{Neff}^k_y\\right) \\] Here, model predicted recaptures are recapture conditioned, which means the predicted proportions are year specific, and represent the proportion of recaptures in each region, \\(\\boldsymbol{\\hat{\\theta}}^k_y = (\\hat{\\theta}^{k}_{y,1},\\dots, \\hat{\\theta}^k_{y,n_r})&#39;\\) \\[\\begin{equation} \\hat{\\theta}^{k}_{y,r} = \\frac{\\widehat{N}^k_{r,y}}{\\sum_r\\widehat{N}^k_{r,y}} \\end{equation}\\] Release conditioned are defined as the proportion of recaptures over all states denoted as \\(i\\), for each release event. All the states, include all regions, and years of recoveries including the non recaptured, where, \\(\\boldsymbol{\\hat{\\theta}}^k = (\\hat{\\theta}^k_i, \\hat{\\theta}^k_2\\dots, \\hat{\\theta}^k_{n_i}) = (\\hat{\\theta}^k_{1,1}, \\hat{\\theta}^k_{1,2}, \\hat{\\theta}^k_{2,2}, \\dots, \\hat{\\theta}^k_{n_y,n_r}, \\hat{\\theta}^k_{NR})\\) is the proportions of all states (Vincent, Brenden, and Bence 2020; Goethel, Legault, and Cadrin 2014), with \\[\\begin{equation} \\hat{\\theta}^{k}_{i} = \\frac{\\widehat{N}^k_{i}}{\\sum_i \\widehat{N}^k_{i}} \\end{equation}\\] Likelihood formulations Multinomial This likelihood has no estimable parameters \\[ \\boldsymbol{X} \\sim \\text{Multinomial}\\left(\\boldsymbol{\\widehat{P}}\\right) \\] To avoid \\(\\widehat{P}_i = 0\\), in which case the multinomial can be undefined if \\(X_i = 0\\) all values of \\(\\widehat{P}_i\\) are run through a posfun function which adds a small constant and penalty to the likelihood. See this TMB issue here or Ben Bolkers write up found here. Dirichlet-Multinomial The Dirichlet-Multinomial distribution used for composition data, with input sample size denoted by \\(n\\), observed proportion for age \\(a\\) denoted by \\(p_a\\) and expected proportions denoted by \\(\\widehat{p}_a\\). There is an estimable parameter denoted by \\(\\theta\\). This follows the linear-parameterisation from Thorson et al. (2017), with the following density function \\[\\begin{equation} f(x) = \\frac{\\Gamma\\left(n + 1\\right)}{\\sum_a n{p}_a + 1}\\frac{\\Gamma\\left(\\theta n\\right) }{\\Gamma\\left(n + \\theta n\\right)}\\prod_{a} \\frac{\\Gamma\\left(n {p}_a + n \\theta \\widehat{p}_a\\right)}{\\Gamma\\left(n \\theta \\widehat{p}_a\\right)} \\end{equation}\\] The effectictive sample size is calcualted as, \\[ n_{eff} = \\frac{1 + \\theta n}{1 + \\theta} \\] Simulating from this distribution is done by first simulating a dirichlet variable, using independent gamma draws (normalised), with shape parameter set as the expected proportion. Then draw from the multinomial with expected proportions based on the dirichlet draw. Lognormal As mentioned in the abundance observation section there are two alternative lognormal forms in the model. Pearon residuals are calculated as \\[ r_i = \\frac{log(O_i/E_i) + 0.5\\sigma_i^2}{\\sigma_i} \\] Projecting Recruitment There are two methods for future recruitment, parametric and empirical. Parametric will simulate from the the lognormal distribution with \\(\\sigma_R\\). Empirical will resample input recruitment deviations between certain years Parametric future_recruitment_type == 0 \\[ \\epsilon_y \\sim \\mathcal{N}\\left(0, \\sigma_R^2 \\right) \\] resulting recruitment multipliers, also termed year class strengths (\\(YCS_y\\)) are bias adjusted \\(YCS_y = \\exp(\\epsilon_y - 0.5\\sigma_R^2)\\) Empirical future_recruitment_type == 1 this will sample with replacement input recruitment deviations between the values specified in year_ndx_for_empirical_resampling. Note elements of year_ndx_for_empirical_resampling are C++ vector dimensions. If year_ndx_for_empirical_resampling = c(0,n_years - 1) this will resample from all input recruitment deviations. if year_ndx_for_empirical_resampling = c(0,9) this will resample from the first 10 input recruitment deviations. if year_ndx_for_empirical_resampling = c((n_years - 9):(n_years - 1)) this will resample from the last 10 input recruitment deviations. Deterministic recruitment future_recruitment_type == 2. This will assume \\(YCS_y = 1\\) which result in the model applying mean recruitment for all future years Fishing Fishing selectivity that was assumed in the last year of the model is used during the projection period. There are two methods users can use for future fishing, assume fishing mortality rates or catches. User specifies F values during projection (unlikely useage) future_fishing_type = 0 populate future_fishing_inputs_trwl and future_fishing_inputs_fixed with F values User specifies Catch values during projection (more likely) future_fishing_type = 1 populate future_fishing_inputs_trwl and future_fishing_inputs_fixed with future catches. An F is calculated based on the hybrid fishing mortality method, which should result in predicted catches close to these but not exact. Example code snippets ## once you have done MLE and evaluated fits to a model ## then you can running the following code to find ## deterministic reference points based on %B0 n_proj_years = 100 regional_spr = find_regional_Fspr(data = data, MLE_report = mle_report, n_years_for_fleet_ratio = 5, percent_Bzero = 40, n_future_years = n_proj_years, verbose = T) # setup projection data proj_data = setup_proj_data(mle_obj = mle_obj, n_proj_years = 100) ## use the Fs from Fspr function proj_data$future_fishing_inputs_trwl = matrix(regional_spr$Fspr * (1 - regional_spr$fixed_gear_F_proportion), byrow = F, ncol = n_proj_years, nrow = n_regions) proj_data$future_fishing_inputs_fixed = matrix(regional_spr$Fspr * regional_spr$fixed_gear_F_proportion, byrow = F, ncol = n_proj_years, nrow = n_regions) # check projection data validate_input_data_and_parameters(data = proj_data, parameters = parameters) # build proj object proj_obj &lt;- MakeADFun(proj_data, parameters, map = map_fixed_pars, DLL=&quot;SpatialSablefishAssessment_TMBExports&quot;, hessian = T, silent = T) # run the projection model with future F&#39;s and MLE parameter values proj_rep = proj_obj$report(mle_spatial$par) # Check the depletion levels are as expected plot_SSB(MLE_report = proj_rep, region_key = region_key, depletion = T) + geom_hline(yintercept = 40, col = &quot;gray&quot;, linetype = &quot;dashed&quot;, linewidth = 1.1) + ylim(0, NA) ## once this checks out, you should run projections with stochasticity in recruitment and parameters estimates ## to get projected quantities with uncertainty. Symbol Notation Symbol Description \\(y\\) Year index \\(T\\) Terminal year of the model \\(s\\) Sex index \\(s \\in \\{1,2\\}\\) \\(a\\) Model age cohort, i.e., \\(a = a_0, a_0 + 1, \\dots\\) \\(a_{1}\\) Recruitment age to the model = 2 \\(a_+\\) Plus-group age class (oldest age considered plus all older ages) \\(n_a\\) Number of age classes modeled \\(a_+ \\ - a_1\\) \\(l\\) length class \\(n_l\\) Number of length classes \\(g\\) gear type index, i.e. longline survey, fixed gear fishery, trawl fishery \\(x\\) log-likelihoos index \\(\\bar{w}_{a,y, s}\\) Average weight at age \\(a\\), year \\(y\\) and sex \\(s\\) \\(\\phi_{a,y}\\) Proportion of female mature by age and year \\(p^s_{y}\\) Proportion of recruits for sex \\(s\\). Often assumed = 0.5 \\(\\ln \\mu_{r}\\) Average log-recruitment \\(p^R_y\\) proportion recruitment male \\(\\ln \\mu_{f}\\) Average log-fishing mortality \\(\\phi_{y,g}\\) annual fishing mortality deviation by gear (log space) \\(\\tau_{y}\\) annual recruitment deviation \\(\\sim LogNormal\\left(0,\\sigma_r\\right)\\) \\(\\sigma_r\\) Recruitment standard deviation \\(N_{a,y,s}\\) Numbers of fish at age \\(a\\) in year \\(y\\) of sex \\(s\\) \\(M\\) Natural mortality \\(F^g_{a,y}\\) Fishing mortality for year \\(y\\), age \\(a\\) and gear \\(g\\) \\(F_{hist}\\) Historical proportion of Fishing mortality \\(Z_{a,y}\\) Total mortality for year \\(y\\), age \\(a\\) \\(=\\sum\\limits_g F^g_{a,y} + M\\) \\(R_{y}\\) Annual recruitment \\(B_{y}\\) Spawning biomass in year \\(y\\) \\(S^g_{a,y,s}\\) Selectivity at age \\(a\\) for gear type \\(g\\) and sex \\(s\\) \\(a_50\\) age at 50% selection for ascending limb \\(d_50\\) age at 50% selection for descending limb \\(\\delta\\) slope/shape parameters for different logistic curves \\(\\boldsymbol{A}\\) ageing-error matrix dimensions \\(n_a \\ \\times \\ n_a\\) \\(\\boldsymbol{A}^l_s\\) age to length conversion matrix by sex. dimensions \\(n_a \\ \\times \\ n_l\\) \\(q_g\\) abundance index catchability coeffecient by gear \\(\\lambda_x\\) Statistical weight (penalty) for component \\(x\\) \\(P^g_{l,y,s}\\) Observed proportions at length for gear \\(g\\) in year \\(y\\) and sex \\(s\\) \\(P^g_{a,y,s}\\) Observed proportions at age for gear \\(g\\) in year \\(y\\) and sex \\(s\\) References "],["tagintegrated-data-and-parameter-descriptions.html", "TagIntegrated data and parameter descriptions data parameters", " TagIntegrated data and parameter descriptions Users need to population a named list containing data inputs and a named list specifying starting values for estimable parameters which are both passed to TMBs MakeADFun function. These sections outline the elements and corresponding dimensions of both data and parameters. data ages vector of ages. Length n_ages years vector of years from start year to current year. length n_years length_bins vector of length bin midpoints. length. n_length_bins n_projections_years integer of future years to project the model n_projyears = n_years + n_projections_years do_projection integer 0 means dont do projection 1 does a stochastic projection (should be turned off during estimation) n_regions integer needs to be greater than or equal to 1 n_surveys integer needs to be greater than or equal to 1. This defines the outer dimension for all survey objects global_rec_devs integer 1 means all regions share the same annual recruitment deviations. 0 means they have separate annual recruitment deviations. This will effect the dimensions of the parameter trans_rec_dev rec_devs_sum_to_zero Should the recruit devs in each region sum to zero? yes = 1, no = 0. I yes then this the parameter trans_rec_dev has one less parameter n_init_rec_devs number of initial n_age_deviations (parameter$ln_init_rec_dev) to multiply against the initial numbers at age to have non equilibrium initial age-structure. A value of zero will not apply these initial devs and expects parameter$ln_init_rec_dev to have length 1. These deviations are applied equally to both male and female. M Natural mortality array with dimensions n_ages \\(\\times\\) n_projyears maturity proportion mature array with dimensions n_ages \\(\\times\\) n_projyears male_mean_weight_by_age male mean weight at age array with dimensions n_ages \\(\\times\\) n_projyears. Units are in kgs, this is because we track millions of fish in the partition, so any weight calculation is in kilo tonnes female_mean_weight_by_age female mean weight at age array with dimensions n_ages \\(\\times\\) n_projyears. Units are in kgs, this is because we track millions of fish in the partition, so any weight calculation is in kilo tonnes male_age_length_transition male age-length transtion matrix for each year. An array with dimensions n_ages \\(\\times\\)n_length_bins \\(\\times\\) n_projyears female_age_length_transition female age-length transtion matrix for each year. An array with dimensions n_ages \\(\\times\\)n_length_bins \\(\\times\\) n_projyears SrType Stock recruitment type 2 = Beverton holt, 3 = average (NO SR) spawning_time_proportion vector of proportions that indicate when during the year spawning occurs. Length = n_projyears apply_fixed_movement integer whether to apply the input fixed_movement_matrix or estimated movement matrix. This was added because the transformation on estimated movement parameters does not allow values to be zero or one so cannot truly apply no movement. That is when I have used this fixed movement do_recruits_move integer specifying whether recruits are applied in the movement dynamic. 1 = yes, 0 = no. fixed_movement_matrix movement matrix with dimensions n_regions \\(\\times\\)n_regions. Rows sum equal to one. prop_F_hist scalar proportion of longline average F that is applied during initialization. F_method integer, if = 0 then we estimate mean and deviation F free parameters, otherwise if equal 1, use newton raphson iterations and solve F F_max scalar Maxium F when using the F_method = 1 F_iterations integer how many newton raphson iterations are done to solve F when F_method = 1 fixed_fishery_catch vector of annual catch for the fixed gear fishery. Units are kilo tonnes trwl_fishery_catch vector of annual catch for the Trawl gear fishery. Units are kilo tonnes fixed_sel_type vector of integers specifying the selectivity type in each time-block length(unique(fixed_sel_by_year_indicator)). Values 0 = logistic, 1 = Double normal, 2 = power function, 3 = alternative logistic formulation, 4 = exponential decay, 5 = double normal with three parameters fixed_sel_by_year_indicator vector of integers specifying which selectivity time-block to apply in each year (C++ indexing so start at zero). Expected length is n_projyears trwl_sel_type vector of integers specifying the selectivity type in each time-block length(unique(trwl_sel_by_year_indicator)). Values 0 = logistic, 1 = Double normal, 2 = power function, 3 = alternative logistic formulation, 4 = exponential decay, 5 = double normal with three parameters trwl_sel_by_year_indicator vector of integers specifying which selectivity time-block to apply in each year (C++ indexing so start at zero). Expected length is n_projyears srv_sel_type vector of integers specifying the selectivity type in each time-block, length(unique(srv_sel_by_year_indicator)) x n_surveys. Values 0 = logistic, 1 = Double normal, 2 = power function, 3 = alternative logistic formulation, 4 = exponential decay, 5 = double normal with three parameters srv_sel_by_year_indicator vector of integers specifying which selectivity time-block to apply in each year (C++ indexing so start at zero). Expected dimension is n_projyears x n_surveys tag_release_event_this_year vector of integers specifying whether tags are released in each year. Length n_years. n_years_with_tag_releases = sum(tag_release_event_this_year) male_tagged_cohorts_by_age Numbers of male tagged fish. Dimension n_ages \\(\\times\\) n_region \\(\\times\\) n_years_with_tag_releases. These are in actual numbers not millions of fish, like the recruitment parameters and other model abundance quantities female_tagged_cohorts_by_age Numbers of female tagged fish. Dimension n_ages \\(\\times\\) n_region \\(\\times\\) n_years_with_tag_releases. These are in actual numbers not millions of fish, like the recruitment parameters and other model abundance quantities n_years_to_retain_tagged_cohorts_for integer, number of years to keep release event information on tag-releases initial_tag_induced_mortality vector or initial tag release mortality with length n_years_with_tag_releases annual_tag_shedding_rate scalar for annual tag-shedding rate ageing_error_matrix ageing error matrix n_ages \\(\\times\\) n_ages fixed_catchatage_indicator an indicator array for fixed gear catch at age observation with dimensions n_regions \\(\\times\\) n_years. A one indicates there is a catch at age observation for the fixed fishery in this region and year. A zero indicates no observation. obs_fixed_catchatage fixed catch at age observation with dimensions n_ages * 2 \\(\\times\\) n_regions \\(\\times\\) n_years. The first dimension represents sex and age with males being the first age block followed by females. This observation is in numbers which is equivalent to proportions times the effective sample size. Predicted proportions will sum = 1 over the age and sex dimension. fixed_catchatage_covar_structure integer, this is a place holder doesnt do anything yet, will be used when there is alternative composition likelihoods. fixed_catchatage_comp_likelihood integer, 0 indicates multinomial, 1 indicates dirichlet-multinomial trwl_catchatlgth_indicator an indicator array for trawl gear catch at length observation with dimensions n_regions \\(\\times\\) n_years. A one indicates there is a catch at length observation for the trawl fishery in this region and year. A zero indicates no observation. obs_trawl_catchatlgth fixed catch at length observation with dimensions n_length_bins * 2 \\(\\times\\) n_regions \\(\\times\\) n_years. The first dimension represents length bin and age with males being the first length block followed by females. This observation is in numbers which is equivalent to proportions times the effective sample size. Predicted proportions will sum = 1 over the length and sex dimension. trwl_catchatlgth_covar_structure integer, this is a place holder doesnt do anything yet, will be used when there is alternative composition likelihoods. trwl_catchatlgth_comp_likelihood integer, 0 indicates multinomial, 1 indicates dirichlet-multinomial fixed_catchatlgth_indicator an indicator array for fixed gear catch at length observation with dimensions n_regions \\(\\times\\) n_years. A one indicates there is a catch at length observation for the fixed gear fishery in this region and year. A zero indicates no observation. obs_fixed_catchatlgth fixed catch at length observation with dimensions n_length_bins * 2 \\(\\times\\) n_regions \\(\\times\\) n_years. The first dimension represents length bin and age with males being the first length block followed by females. This observation is in numbers which is equivalent to proportions times the effective sample size. Predicted proportions will sum = 1 over the length and sex dimension. fixed_catchatlgth_covar_structure integer, this is a place holder doesnt do anything yet, will be used when there is alternative composition likelihoods. fixed_catchatlgth_comp_likelihood integer, 0 indicates multinomial, 1 indicates dirichlet-multinomial srv_catchatage_indicator an indicator array for survey catch at age observation with dimensions n_regions \\(\\times\\) n_years \\(\\times\\) n_surveys. A one indicates there is a catch at age observation for the longline survey in this region and year. A zero indicates no observation. obs_srv_catchatage Observed catch at age observation for surveys with dimensions n_ages * 2 \\(\\times\\) n_regions \\(\\times\\) n_years \\(\\times\\) n_surveys. The first dimension represents age and age with males being the first age block followed by females. This observation is in numbers which is equivalent to proportions times the effective sample size. Predicted proportions will sum = 1 over the age and sex dimension. srv_catchatage_covar_structure integer, this is a place holder doesnt do anything yet, will be used when there is alternative composition likelihoods. srv_catchatage_comp_likelihood vector of integers of length`n_surveys, 0 indicates multinomial, 1 indicates dirichlet-multinomial srv_bio_indicator an indicator array for survey abundance (or biomass) observation with dimensions n_regions \\(\\times\\) n_years\\(\\times\\) `n_surveys. A one indicates there is an abundance observation for the longline survey in this region and year. A zero indicates no observation. obs_srv_bio survey abundance observation n_regions \\(\\times\\) n_years\\(\\times\\) `n_surveys. This observation is in numbers (000s) which is equivalent to proportions times the effective sample size. Predicted proportions will sum = 1 over the age and sex dimension. obs_srv_se Standard error for the survey abundance observation same dimension as observation srv_bio_likelihood vector of integers of length n_surveys, a value of 0 is the old lognormal call (SE is normal distribution converted to CV by the likelihood evaluation), a value of 1 uses thedlnorm` call, standard error are specified in as the lognormal disribution (different to the other value) srv_obs_is_abundance vector of integers integer of length `n_surveys, a value of 0 indicates the observation is biomass or weight. A value of 1 indicates the observation is abundance or numbers srv_q_by_year_indicator indicator vector, this indicates how many time-blocks for time-varying catchabilities are available. Each element links an element of the parameter trans_srv_q for a year. srv_q_transformation vector of integers of length n_surveys, indicates what transformation is used fortrans_srv_q`. 0 indicates log, 1 indicates logistic where q is bound between 0 and 1. q_is_nuisance vector of integers of length a 0 indicates q is calculated as a free parameter trans_srv_q. If it is equal to 1 then you shouldnt estimate trans_srv_q because it calculates the survey catchability values based on MLE values conditional on input values. tag_recovery_indicator_by_year an indicator vector for tag-recovery observations has length n_years. A one indicates there is a tag recovery observation in this year. A zero indicates no observation. This object is used to define n_tag_recovery_years = sum(tag_recovery_indicator_by_year), which links to other tag-recovery structures. This input parameter is not used when tag_likelihood %in% c(2). tag_recovery_indicator an indicator vector for specific tag-release/tag-recovery observations to store. Dimensions of this will depend on tag_likelihood. If tag_likelihood %in% c(0,1) then the dimension is n_tag_release_events \\(\\times\\) n_regions \\(\\times\\) n_tag_recovery_years. If tag_likelihood %in% c(2) then the dimensions are n_years \\(\\times\\) n_regions this indicates the release event that we wont to save all possible recovery predictions for. obs_tag_recovery tag-recovery observations. Dimension will depend on tag_likelihood. If tag_likelihood %in% c(0,1) then the dimensions are n_tag_release_events \\(\\times\\) n_regions \\(\\times\\) n_tag_recovery_years. Units are numbers (can be non-integer) of recoveries. If tag_likelihood %in% c(2) then the dimensions are n_regions * n_years_to_retain_tagged_cohorts_for + 1 \\(\\times\\) n_regions \\(\\times\\) n_years. The first dimensions relate to a release event, the last dimension relates to all possible recovery events and plus one for the not recovered group. tag_likelihood integer specifying the tag-likelihood, 0 = Poisson, 1 = negative binomial, 2 = Multinomial (release conditioned) evaluate_tag_likelihood integer specifying whether to evaluate the likelihood (=1) or not (=0) useful when asking the model to calculate predicted values but not evaluate the likelihood for debugging. future_recruitment_type integer specifying the future recruitment deviation process. 0 = simulate from lognormal distribution with using the sigma R, 1 = empirically re sample input recruitment deviations, 2 = recruitment multiplers = 1 which results in the model applying mean recruitment for all future years year_ndx_for_empirical_resampling integer vector specifying years to empirically resample from if future_recruitment_type == 1, then this specifies the upper and lower index to resample e.g., year_ndx_for_empirical_resampling = c(0,n_years - 1) then this would resample from all years if year_ndx_for_empirical_resampling = c((n_years - 10), n_years - 1), then this would resample from the last ten years of the input recruitment deviations future_fishing_type integer 0 means users have supplied fishing mortality rates in future fishing input containers. If 1 then user supplied catchs in future fishing input containers. future_fishing_inputs_fixed an array with dimensions n_regions \\(\\times\\) n_projections_years. Will be Fs or catches fir the fixed gear fishery depending on the value of future_fishing_type future_fishing_inputs_trwl an array with dimensions n_regions \\(\\times\\) n_projections_years. Will be Fs or catches fir the trawl gear fishery depending on the value of future_fishing_type Additional data inputs for TagIntegratedValidate apply_Z_on_tagged_fish integer 0 no, 1 yes apply_fishery_tag_reporting integer 0 no, 1 yes apply_tag_reporting_rate integer 0 no, 1 yes parameters ln_mean_rec vector of natural logarithm of mean recruitment (units are log millions) for each region. length n_regions. trans_rec_dev array of recruitment deviations. if global_rec_devs = 1 then this has dimension 1 \\(\\times\\) n_years, else it has a row for each region and dimension n_regions\\(\\times\\) n_years ln_init_rec_dev vector of initial devs to multiple to initial numbers at age for non-equilibrium age-structure. Must have length equal to data$n_init_rec_devs. The first dev, corresponds to the second age we the last value gets applied to all successive ages i.e., if length(ln_init_rec_dev) = 10, the first value numbers_at_age[2] * exp(ln_init_rec_dev[1]), and numbers_at_age[11:n_ages] * exp(ln_init_rec_dev[10]) ln_fixed_sel_pars array of log selectivity parameters for fixed gear fishery with dimension n_time_blocks\\(\\times\\) max(sel parameters)\\(\\times\\) 2 (for each sex) male parameters first followed by female. The number of time-blocks is defined by the data parameter data$fixed_sel_by_year_indicator and max selectivity parameters controlled by data$fixed_sel_type which defines the selectivity shape and thus number of parameters. ln_trwl_sel_pars array of log selectivity parameters for trawl gear fishery with dimension n_time_blocks\\(\\times\\) max(sel parameters)\\(\\times\\) 2 (for each sex) male parameters first followed by female. The number of time-blocks is defined by the data parameter data$trwl_sel_by_year_indicator and max selectivity parameters controlled by data$trwl_sel_type which defines the selectivity shape and thus number of parameters. transformed_movement_pars array of movement parameters that are transformed in the simplex space. It has dimension n_regions - 1 \\(\\times\\) n_regions. Use the packages inbuilt simplex() and restoresimplex() functions to change a vector that sums to one to a simplex with n-1 parameters. ln_fixed_F_avg scalar for the log average fishing mortality of the fixed gear fishery. Should be not estimated if data$F_method = 1 ln_fixed_F_devs annual fishing mortality deviations from ln_fixed_F_avg. Expected dimensions are n_regions \\(\\times\\) n_years. Should be not estimated if data$F_method = 1 ln_trwl_F_avg scalar for the log average fishing mortality of the fixed gear fishery. Should be not estimated if data$F_method = 1 ln_trwl_F_devs annual fishing mortality deviations from ln_trwl_F_avg. Expected dimensions are n_regions \\(\\times\\) n_years. Should be not estimated if data$F_method = 1 ln_init_F_avg scalar for the log fishing mortality applied during initialisation. ln_catch_sd scalar for the log catch standard deviation trans_srv_q ann array of transformed catchabilities parameters. The type of transformation will depend on srv_q_transformation. Should have dimension n_regions\\(\\times\\) length(unique(data$srv_q_by_year_indicator)) (number of time-blocks) \\(\\times\\) n_surveys ln_srv_sel_pars array of log selectivity parameters for surveys with dimension n_time_blocks\\(\\times\\) max(sel parameters)\\(\\times\\) 2 (for each sex) male parameters first followed by female \\(\\times\\) n_surveys. The number of time-blocks is defined by the data parameter data$srv_sel_by_year_indicator and max selectivity parameters controlled by data$srv_sel_type which defines the selectivity shape and thus number of parameters. logistic_tag_reporting_rate logistic tag-reporting rates. Expected dimensions are n_regions \\(\\times\\) n_tag_recovery_years. ln_tag_phi scalar which is the log of the dispersion parameter. Only used if data$tag_likelihood == 1 i.e. the negative binomial distribution is assumed. ln_sigma_R scalar which is the log standard deviation for the recruitment prior/penalty ln_sigma_init_devs scalar which is the log standard deviation for the initial age deviation prior/penalty trans_trwl_catchatlgth_error vector of observation error parameters for trawl catch at length observation Depends on data$trwl_catchatlgth_comp_likelihood. If data$trwl_catchatlgth_comp_likelihood == 0 then this assumes multinomial and this parameter should not be estimated. if data$trwl_catchatlgth_comp_likelihood == 1 the this assumes the Dirichlet-multinomial distribution and this should have length 1 and is the log \\(\\theta\\) parameter. trans_fixed_catchatlgth_error vector of observation error parameters for fixed gear fishery catch at length observation. Depends on data$fixed_catchatlgth_comp_likelihood. If data$fixed_catchatlgth_comp_likelihood == 0 then this assumes multinomial and this parameter should not be estimated. if data$fixed_catchatlgth_comp_likelihood == 1 the this assumes the Dirichlet-multinomial distribution and this should have length 1 and is the log \\(\\theta\\) parameter. trans_fixed_catchatage_error vector of observation error parameters for fixed catch at age observation. Depends on data$fixed_catchatage_comp_likelihood. If data$fixed_catchatage_comp_likelihood == 0 then this assumes multinomial and this parameter should not be estimated. if data$fixed_catchatage_comp_likelihood == 1 the this assumes the Dirichlet-multinomial distribution and this should have length 1 and is the log \\(\\theta\\) parameter. trans_srv_catchatage_error vector of observation error parameters for survey catch at age observation. Depends on data$srv_catchatage_comp_likelihood. If data$srv_catchatage_comp_likelihood == 0 then this assumes multinomial and this parameter should not be estimated. if data$srv_catchatage_comp_likelihood == 1 the this assumes the Dirichlet-multinomial distribution and this should have length 1 and is the log \\(\\theta\\) parameter. logistic_prop_recruit_male vector logistic proportions male for recruitment. Length: n_years trans_SR_pars vector of stock recruitment parameters. If SrType == 2 then this a vector of length 1 containing the logistic transformed steepness parameter. This is to make sure steepness is bound between 0 and 1. The only other SrType allowed is average i.e. no SR and thus no SR parameters. In future this will be extended to include Ricker and other BH parameterisations. "],["assessment-data-and-parameter-descriptions.html", "Assessment data and parameter descriptions data parameters", " Assessment data and parameter descriptions Users need to population a named list containing data inputs and a named list specifying starting values for estimable parameters which are both passed to TMBs MakeADFun function. This section outlines the elements and corresponding dimensions of both data and parameters. data ages vector of ages. Length n_ages years vector of years from start year to current year. length n_years length_bins vector of length bin midpoints. length. n_length_bins n_projections_years integer of future years to project the model n_projyears = n_years + n_projections_years do_projection integer 0 means dont do projection 1 does a stochastic projection (should be turned off during estimation) n_init_rec_devs number of initial n_age_deviations (parameter$ln_init_rec_dev) to multiply against the initial numbers at age to have non equilibrium initial age-structure. A value of zero will not apply these initial devs and expects parameter$ln_init_rec_dev to have length 1. These deviations are applied equally to both male and female. M Natural mortality array with dimensions n_ages \\(\\times\\) n_projyears maturity proportion mature array with dimensions n_ages \\(\\times\\) n_projyears male_mean_weight_by_age male mean weight at age array with dimensions n_ages \\(\\times\\) n_projyears. Units are in kgs, this is because we track millions of fish in the partition, so any weight calculation is in kilo tonnes female_mean_weight_by_age female mean weight at age array with dimensions n_ages \\(\\times\\) n_projyears. Units are in kgs, this is because we track millions of fish in the partition, so any weight calculation is in kilo tonnes male_age_length_transition male age-length transtion matrix for each year. An array with dimensions n_ages \\(\\times\\)n_length_bins \\(\\times\\) n_projyears female_age_length_transition female age-length transtion matrix for each year. An array with dimensions n_ages \\(\\times\\)n_length_bins \\(\\times\\) n_projyears SrType Stock recruitment type 2 = Beverton holt, 3 = average (NO SR) spawning_time_proportion vector of proportions that indicate when during the year spawning occurs. Length = n_projyears ll_fishery_catch vector of annual catch for the fixed gear fishery. Units are kilo tonnes trwl_fishery_catch vector of annual catch for the Trawl gear fishery. Units are kilo tonnes parameters ln_mean_rec scalar of natural logarithm of mean recruitment (units are log millions). "],["how-to-use-spatialsablefishassessment-in-a-mse.html", "How to use SpatialSablefishAssessment in a MSE", " How to use SpatialSablefishAssessment in a MSE ## get MLE quantities mle_report = my_model$report(mle_optim$par) ######### ## Plot interesting ## Model quantities i.e., recruitment SSBs model fits etc ######### ## movement assumption plot_movement(mle_report, region_key = region_key) # starting values plot_movement(OM_report, region_key) # plot selectivities plot_selectivities(mle_report) # starting values plot_selectivities(OM_report) ## Regional SSBs ssb_plt = plot_SSB(mle_report, region_key = region_key) ssb_plt ## sum SSB over all regions ggplot(ssb_plt$data %&gt;% group_by(Year) %&gt;% summarise(total_ssb = sum(SSB)), aes(x = Year, y = total_ssb)) + geom_line(linewidth = 1.1) + ylim(0,NA) ## plot F&#39;s plot_fishing_mortalities(MLE_report = mle_report, region_key = region_key) ## plot fits to observations # catch and index plot_catch_fit(MLE_report = mle_report, region_key = region_key) + facet_wrap(label~Region, ncol = n_regions) + ylab(&quot;Catch (mt)&quot;) plot_index_fit(MLE_report = mle_report, region_key = region_key) # survey AFs first_year_set = c(1981, seq(from = 1985, to = 1993, by = 2), 1996:1999) plot_AF(MLE_report = mle_report, region_key = region_key, label = &quot;srv_dom_ll&quot;, subset_years = first_year_set, sex = &quot;male&quot;) + ggtitle(&quot;Male survey AF&quot;) + guides(shape = &quot;none&quot;, linetype = &quot;none&quot;) + ylim(0,20) plot_AF(MLE_report = mle_report, region_key = region_key, label = &quot;srv_dom_ll&quot;, subset_years = first_year_set, sex = &quot;female&quot;) + ggtitle(&quot;Female survey AF&quot;) + guides(shape = &quot;none&quot;, linetype = &quot;none&quot;) # fishery LFs # Fixed gear plot_LF(MLE_report = mle_report, region_key = region_key, label = &quot;fixed&quot;, subset_years = 1991:1999, sex = &quot;male&quot;) + ggtitle(&quot;Male fixed LF&quot;) + guides(shape = &quot;none&quot;, linetype = &quot;none&quot;) plot_LF(MLE_report = mle_report, region_key = region_key, label = &quot;fixed&quot;, subset_years = 1991:1999, sex = &quot;female&quot;) + ggtitle(&quot;Female fixed LF&quot;) + guides(shape = &quot;none&quot;, linetype = &quot;none&quot;) # plot by tag releases event tag_fits_by_age_sex = get_tag_recovery_obs_fitted_values(mle_report, region_key = region_key) tag_fits = tag_fits_by_age_sex %&gt;% group_by(release_event, unique_recovery_id) %&gt;% summarise(observed = sum(observed), predicted = sum(predicted), recovery_year = unique(recovery_year), recovery_region = unique(recovery_region), release_region = unique(release_region), release_year = unique(release_year)) tag_fits$resid = tag_fits$observed - tag_fits$predicted tag_fits$stand_resid = tag_fits$resid / tag_fits$predicted tag_fits$resid_sign = ifelse(tag_fits$resid &lt; 0, &quot;negative&quot;, &quot;positive&quot;) unique_release_events = unique(tag_fits$release_event) gplt = ggplot(tag_fits %&gt;% filter(release_event %in% unique_release_events[1:16]), aes(x = recovery_year, y = recovery_region)) + geom_point(aes(size = abs(stand_resid), col = resid_sign)) + labs(x = &quot;Recovery year&quot;, y = &quot;Recovery region&quot;, size = &quot;Pearson residuals&quot;) + theme_bw() + scale_size_area() + facet_wrap(~release_event) + scale_x_discrete(breaks = every_nth(n = 5)) "],["contributing-to-spatialsablefishassessment.html", "Contributing to SpatialSablefishAssessment Adding a new R dependency Tips", " Contributing to SpatialSablefishAssessment This is an open source project and we encourage users to make changes and help develop the model further. Any commit to the Github page will trigger the Github actions to check the R package which includes installing it, running unit-tests and building the Gitbook which then will be publicly available. Before commiting to this repository it is recommended to run all these tasks locally. The Github repository contains a R script called BuildPackage.R which contains most of the calls that are triggered by the Github actions. When editing TMB code and recompiling you need to go into the src/ directory and delete any files with the extension .dll or .o. You should also do this in the src/TMB directory. If you dont delete these libraries sometimes the pkgbuild::compile_dll() wont recompile the source code with the updated changes. It is best to get into the habit of doing this when dealing with the TMB source code. Any model that is added, should be able to be unit-tested. For TagIntegrated model I created a mirror model called TagIntegratedValidate which has heaps more switches which I didnt want in the production version, but needed to validate isolated functionality. Although this creates duplicate code bases I still think it is the best approach. When you do this it is recommended that you add a unit-test which checks the production and validation model are the same. This will tell you when you change functionality in one of the models and not the other, thus keeping them compatible and the unit-tests trustworthy. Adding a new R dependency All external dependencies are described in the R/SpatialSablefishAssessment-package.R. I try to import specific functions from packages using the following syntax #' @importFrom package function i.e., #' @importFrom ggplot2 geom_point So, if you build a function which uses a function from say dplyr or ggplot2 that isnt in SpatialSablefishAssessment-package.R. You will need to add it there. If you want to use functionality from another library then you will also need to update the DESCRIPTION file Tips You can create a new model by adding a completely new model into the R package by including an new .hpp file in the src/TMB directory. To allow the R package access to this new model, modify the file called SpatialSablefishAssessment_TMBExports.cpp which is also located in the src/TMB directory. In your new .hpp file you can use/call any function that defined in the files found at inst/include directory. These contain selectivity functions and other useful transformation functions that are shared across all models. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
